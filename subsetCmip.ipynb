{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import glob\n",
    "from cdo import *\n",
    "import os\n",
    "import sys\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "cdo = Cdo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import state vector file using geopandas\n",
    "states_url = 'http://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_040_00_5m.json'\n",
    "states_gdf = gpd.read_file(states_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset Parameters\n",
    "# Slice/Subset data down further based on latitutde (-90 -- +90), longitude (0 -- 360)\n",
    "lat_bnds, lon_bnds = [23, 57], [230, 265]\n",
    "\n",
    "baseDir='/glade/scratch/currierw/ACCESS1-0/historical/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need a regular grid (base) for which we want to transform the `tos` data onto. Let's choose orography\n",
    "# tos = sea surface temperature [K]\n",
    "regrdFiles=glob.glob(baseDir+'tos*regrd.nc')\n",
    "if len(regrdFiles) == 0 :    \n",
    "    fBase=baseDir+'orog_fx_ACCESS1-0_historical_r0i0p0.nc'\n",
    "    cdo.griddes(\"-f \"+fBase+\" >\"+baseDir+\"grid.txt\")\n",
    "\n",
    "    fNames=glob.glob(baseDir+'tos*.nc') # get all base sea surface temperature variables\n",
    "    for files in fNames:\n",
    "        fTmp=os.path.splitext(files)[0] # remove file extension\n",
    "        cdo.remapcon(\"grid.txt \", input=files, output=fTmp+\"_regrd.nc\", options=\"-f nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Choose lat and lon\n",
    "lat_bnds, lon_bnds  = [23, 57],                      [230, 265]                      # Slicing for Temperature, HUS, Ps etc. (Theta Values)\n",
    "lat_bndsV,lon_bndsV = [lat_bnds[0]-1,lat_bnds[1]+1], [lon_bnds[0], lon_bnds[1]]      # Slciing for V winds (north-south) add 1 degree buffer to south and north\n",
    "lat_bndsU,lon_bndsU = [lat_bnds[0],lat_bnds[1]],     [lon_bnds[0]-1, lon_bnds[1]+1]  # Slicing for U winds (east-west) add 1 degree buffer to west and east\n",
    "\n",
    "#### Data\n",
    "\n",
    "# Choose U, V, Ta, Hus files from the same time-period\n",
    "fNameVa  = baseDir+'va_6hrLev_ACCESS1-0_historical_r1i1p1_1980010106-1981010100.nc'\n",
    "fNameUa  = baseDir+'ua_6hrLev_ACCESS1-0_historical_r1i1p1_1980010106-1981010100.nc'\n",
    "fNameTa  = baseDir+'ta_6hrLev_ACCESS1-0_historical_r1i1p1_1980010106-1981010100.nc'\n",
    "fNameHus = baseDir+'hus_6hrLev_ACCESS1-0_historical_r1i1p1_1980010106-1981010100.nc'\n",
    "fNamePs  = baseDir+'ps_6hrLev_ACCESS1-0_historical_r1i1p1_1980010106-1990010100.nc'\n",
    "fNameTos  = baseDir+'tos_*_regrd.nc'\n",
    "fNamePrec = baseDir+'prc_*.nc'\n",
    "\n",
    "# open the datasets (ds) with xarray\n",
    "vads  = xr.open_dataset(fNameVa)\n",
    "uads  = xr.open_dataset(fNameUa) \n",
    "tads  = xr.open_dataset(fNameTa) \n",
    "husds = xr.open_dataset(fNameHus)\n",
    "tosds = xr.open_mfdataset(fNameTos,combine='by_coords')\n",
    "prcds = xr.open_mfdataset(fNamePrec,combine='by_coords')\n",
    "\n",
    "#### Processing\n",
    "\n",
    "# Resample Sea Surface Temp Data to 6 Hour data from Daily Mean - does forward fill\n",
    "tos6Hour  = tosds.resample(time='6H').ffill()\n",
    "tosOut    = tos6Hour['tos'].sel(time=slice(vads.time[0],vads.time[-1]))  # Time slice based on 6H data file\n",
    "tosds_sub = tosOut.sel(lat=slice(*lat_bnds), lon=slice(*lon_bnds)) # subset the hus data spatially\n",
    "\n",
    "# Precipitation is 3D, only time,lat,lon - stored in longer time files in 3 hr data\n",
    "prcds_sub  = prcds.sel(lat=slice(*lat_bnds), lon=slice(*lon_bnds))  # Subset spatially first\n",
    "prc6HrSub  = prcds_sub['prc'].resample(time='6H').sum()             # Aggregate from 3H to 6H\n",
    "prc6HrSub  = prc6HrSub.sel(time=slice(vads.time[0],vads.time[-1]))  # Time slice based on 6H data file\n",
    "\n",
    "# Surface Air Pressure [Pa] - (time,lat,lon)\n",
    "psds       = xr.open_dataset(fNamePs)\n",
    "psds_tsub  = psds.sel(time=slice(vads.time[0],vads.time[-1]))           # Time slice based on 6H data file\n",
    "psds_sub   = psds_tsub.sel(lat=slice(*lat_bnds), lon=slice(*lon_bnds))  # Subset air pressure data\n",
    "\n",
    "# Slice/Subset 4D data\n",
    "vads_sub  = vads.sel(lat=slice(*lat_bndsV), lon=slice(*lon_bndsV))  # subset the Va data spatially\n",
    "uads_sub  = uads.sel(lat=slice(*lat_bndsU), lon=slice(*lon_bndsU))  # subset the Ua data spatially\n",
    "tads_sub  = tads.sel(lat=slice(*lat_bnds),  lon=slice(*lon_bnds))  # subset the ta data spatially\n",
    "husds_sub = husds.sel(lat=slice(*lat_bnds), lon=slice(*lon_bnds)) # subset the hus data spatially\n",
    "\n",
    "# print(\"\\nSize of 4D Files\")\n",
    "# print(\"\\nSubsetted Air Temperautre Data Size =\")\n",
    "# print(tads_sub['ta'].shape)\n",
    "# print(\"\\nSubsetted Humidity Data Size =\")\n",
    "# print(husds_sub['hus'].shape)\n",
    "# print(\"\\nSubsetted V Winds Data Size =\")\n",
    "# print(vads_sub['va'].shape)\n",
    "# print(\"\\nSubsetted U Winds Data Size =\")\n",
    "# print(uads_sub['ua'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U east-west wind longitude data were sliced correctly\n",
      "V north-south wind latitude data were sliced correctly\n"
     ]
    }
   ],
   "source": [
    "if tads_sub['lon'][0]-uads_sub['lon'][0] > 0 and tads_sub['lon'][-1]-uads_sub['lon'][-1] < 0 :\n",
    "    print('U east-west wind longitude data were sliced correctly')\n",
    "else:\n",
    "    sys.exit(\"The longitude data for the U data were not sliced correctly\")\n",
    "        \n",
    "if tads_sub['lat'][0]-vads_sub['lat'][0] > 0 and tads_sub['lat'][-1]-vads_sub['lat'][-1] < 0 :\n",
    "    print('V north-south wind latitude data were sliced correctly')\n",
    "else:\n",
    "    sys.exit(\"The longitude data for the U data were not sliced correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpolating Data\n"
     ]
    }
   ],
   "source": [
    "# Interpolate data from staggered grid to temperature grid\n",
    "print(\"\\nInterpolating Data\")\n",
    "uads_subI = uads_sub.interp(lat=tads_sub['lat'], lon=tads_sub['lon'])\n",
    "vads_subI = vads_sub.interp(lat=tads_sub['lat'], lon=tads_sub['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Model Level Heights\n"
     ]
    }
   ],
   "source": [
    "# Calculate the model level heights [m]\n",
    "z_t=tads_sub.lev+(tads_sub.b*tads_sub.orog)\n",
    "print('\\nCalculating Model Level Heights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Convert from Specific Humidity to Water Vapor Mixing Ratio\n"
     ]
    }
   ],
   "source": [
    "# Calculate water vapor mixing ratio (w/Qv) [kg/kg] from specific humdiity\n",
    "print('\\n Convert from Specific Humidity to Water Vapor Mixing Ratio')\n",
    "husds_sub['Qv'] = husds_sub['hus']/(1-husds_sub['hus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;ps&#x27; (time: 1464, lat: 27, lon: 19)&gt;\n",
       "[751032 values with dtype=float32]\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1980-01-01T06:00:00 ... 1981-01-01\n",
       "  * lat      (lat) float64 23.75 25.0 26.25 27.5 28.75 ... 52.5 53.75 55.0 56.25\n",
       "  * lon      (lon) float64 230.6 232.5 234.4 236.2 ... 258.8 260.6 262.5 264.4\n",
       "Attributes:\n",
       "    standard_name:     surface_air_pressure\n",
       "    long_name:         Surface Air Pressure\n",
       "    comment:           surface pressure, not mean sea level pressure\n",
       "    units:             Pa\n",
       "    cell_measures:     area: areacella\n",
       "    history:           2012-05-19T04:44:56Z altered by CMOR: replaced missing...\n",
       "    associated_files:  baseURL: http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation...</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'ps' (time: 1464, lat: 27, lon: 19)>\n",
       "[751032 values with dtype=float32]\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1980-01-01T06:00:00 ... 1981-01-01\n",
       "  * lat      (lat) float64 23.75 25.0 26.25 27.5 28.75 ... 52.5 53.75 55.0 56.25\n",
       "  * lon      (lon) float64 230.6 232.5 234.4 236.2 ... 258.8 260.6 262.5 264.4\n",
       "Attributes:\n",
       "    standard_name:     surface_air_pressure\n",
       "    long_name:         Surface Air Pressure\n",
       "    comment:           surface pressure, not mean sea level pressure\n",
       "    units:             Pa\n",
       "    cell_measures:     area: areacella\n",
       "    history:           2012-05-19T04:44:56Z altered by CMOR: replaced missing...\n",
       "    associated_files:  baseURL: http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psds_sub['ps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating new dataset\n",
      "\n",
      "Created new dataset\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'now' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-aea79810d4f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created new dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mdate_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Condensed/Merged File Created'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%m/%d/%Y, %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'now' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating New Dataset\n",
    "print(\"\\nCreating new dataset\\n\")\n",
    "\n",
    "# Create New Datasets that's just the datasets with dimensions and coordinates\n",
    "\n",
    "######## Terrain Height\n",
    "ds_orog = xr.Dataset({\"HGT\":((\"lat\",\"lon\"),tads_sub.orog)},\n",
    "                 coords={\"lat\":tads_sub.lat,\"lon\":tads_sub.lon})\n",
    "ds_orog['HGT'].attrs['standard_name'] = 'Terrain Height'\n",
    "ds_orog['HGT'].attrs['long_name']     = 'Terrain Height'\n",
    "ds_orog['HGT'].attrs['units']         = 'm'\n",
    "ds_orog['HGT'].attrs['Processing Note'] = 'Provided from temeprature dataset - orogoraphy variable'\n",
    "\n",
    "######## 3D Model Level Heights [m]\n",
    "ds_Z    = xr.Dataset({\"Z\":((\"lev\",\"lat\",\"lon\"),z_t)},\n",
    "                 coords={\"lev\":tads_sub.lev,\"lat\":tads_sub.lat,\"lon\":tads_sub.lon})\n",
    "ds_Z['Z'].attrs['standard_name'] = '3D model level heights'\n",
    "ds_Z['Z'].attrs['long_name'] = '3D Model Level Heights'\n",
    "ds_Z['Z'].attrs['units'] = 'm' \n",
    "ds_Z['Z'].attrs['Processing Note'] = 'Calculated using temperature lev coordinates, b values, and orogoraphy varaibles. Z = lev + b * orog' \n",
    "\n",
    "######## Surface Air Pressure [Pa]\n",
    "ds_Ps   = xr.Dataset({\"Ps\":((\"time\",\"lat\",\"lon\"),psds_sub.ps)},\n",
    "                 coords={\"time\":psds_sub.time,\"lat\":psds_sub.lat,\"lon\":psds_sub.lon})\n",
    "ds_Ps['Ps'].attrs = psds_sub.ps.attrs\n",
    "\n",
    "######## Sea Surface Temeperature [K]\n",
    "ds_SST  = xr.Dataset({\"SST\":((\"time\",\"lat\",\"lon\"),tosds_sub)},\n",
    "                 coords={\"time\":tosds_sub.time,\"lat\":tosds_sub.lat,\"lon\":tosds_sub.lon})\n",
    "ds_SST['SST'].attrs = tosds['tos'].attrs\n",
    "ds_SST['SST'].attrs['Processing Note'] = 'Daily data forward filled to 6H data' \n",
    "\n",
    "######## Precipitation [kg m-2 s-1]\n",
    "ds_prec = xr.Dataset({\"prec\":((\"time\",\"lat\",\"lon\"),prc6HrSub)},\n",
    "                 coords={\"time\":tads_sub.time,\"lat\":tads_sub.lat,\"lon\":tads_sub.lon})\n",
    "ds_prec['prec'].attrs['standard_name'] = prcds_sub['prc'].attrs['standard_name']\n",
    "ds_prec['prec'].attrs['long_name'] = prcds_sub['prc'].attrs['long_name']\n",
    "ds_prec['prec'].attrs['comment'] = 'at surface. This is a 6-hour mean convective preciptiation'\n",
    "ds_prec['prec'].attrs['units'] = prcds_sub['prc'].attrs['units']\n",
    "ds_prec['prec'].attrs['cell_methods'] = prcds_sub['prc'].attrs['cell_methods']\n",
    "ds_prec['prec'].attrs['cell_measures'] = prcds_sub['prc'].attrs['cell_measures']\n",
    "ds_prec['prec'].attrs['associated_files'] = prcds_sub['prc'].attrs['associated_files']\n",
    "ds_prec['prec'].attrs['Processing Note'] = 'Resample from 3H data to 6H data using the sum between time-steps'\n",
    "\n",
    "######## Air Temperature [K[]]\n",
    "ds_T = xr.Dataset({\"T\":((\"time\",\"lev\",\"lat\",\"lon\"),tads_sub.ta)},\n",
    "                  coords={\"time\":tads_sub.time,\"lev\":tads_sub.lev,\"lat\":tads_sub.lat,\"lon\":tads_sub.lon})\n",
    "ds_T['T'].attrs = tads_sub.ta.attrs\n",
    "\n",
    "######## Water Vapor Mixing Ratio [kg/kg]\n",
    "ds_Qv = xr.Dataset({\"Qv\":((\"time\",\"lev\",\"lat\",\"lon\"),husds_sub.Qv)},\n",
    "                   coords={\"time\":husds_sub.time,\"lev\":husds_sub.lev,\"lat\":husds_sub.lat,\"lon\":husds_sub.lon})\n",
    "ds_Qv['Qv'].attrs['standard_name'] = 'Water Vapor Mixing Ratio'\n",
    "ds_Qv['Qv'].attrs['long_name'] = 'Water Vapor Mixing Ratio'\n",
    "ds_Qv['Qv'].attrs['units'] = 'kg/kg'\n",
    "ds_Qv['Qv'].attrs['cell measures'] = husds_sub['hus'].attrs['cell_measures']\n",
    "ds_Qv['Qv'].attrs['history'] = husds_sub['hus'].attrs['history']\n",
    "ds_Qv['Qv'].attrs['associated_files'] = husds_sub['hus'].attrs['associated_files']\n",
    "ds_Qv['Qv'].attrs['Processing Note'] = 'Calculated from specific humidity (q) data Qv = q/1-q'\n",
    "\n",
    "######## North South Wind Speeds [m s-1]\n",
    "ds_v = xr.Dataset({\"V\":((\"time\",\"lev\",\"lat\",\"lon\"),vads_subI.va)},\n",
    "                  coords={\"time\":vads_subI.time,\"lev\":tads_sub.lev,\"lat\":vads_subI.lat,\"lon\":vads_subI.lon})\n",
    "ds_v['V'].attrs = vads_subI.va.attrs\n",
    "ds_v['V'].attrs['Processing Note'] = 'Interpolated/Regrided from staggered north-south grid - one additional row offset by 1/2 a grid cell in latitude to the temperature grid'\n",
    "\n",
    "######## East Wind Wind Speeds [m s-1]\n",
    "ds_u = xr.Dataset({\"U\":((\"time\",\"lev\",\"lat\",\"lon\"),uads_subI.ua)},\n",
    "                  coords={\"time\":uads_subI.time,\"lev\":tads_sub.lev,\"lat\":uads_subI.lat,\"lon\":uads_subI.lon})\n",
    "ds_u['U'].attrs = uads_subI.ua.attrs\n",
    "ds_u['U'].attrs['Processing Note'] = 'Interpolated/Regrided from staggered east-west grid - one additional column offset by 1/2 a grid cell in longitude to the temperature grid'\n",
    "                     \n",
    "# Make a new dataset\n",
    "ds = xr.merge([ds_orog, ds_Z, ds_Ps, ds_SST, ds_prec, ds_T, ds_Qv, ds_v, ds_u])\n",
    "\n",
    "print(\"Created new dataset\")\n",
    "date_time = datetime.datetime.now()\n",
    "ds.attrs['Condensed/Merged File Created'] = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "ds.attrs = tads.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "p = ds['T'][0,0,:,:].plot(x='lon', y='lat',transform=ccrs.PlateCarree(),subplot_kws={'projection': ccrs.PlateCarree()})\n",
    "ax.coastlines();ax.gridlines();ax.add_geometries(states_gdf.geometry, crs = ccrs.PlateCarree(),facecolor='none', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.to_netcdf('tempOut.nc')\n",
    "# File Out for one year is 663M\n",
    "# 150 years = 100 gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating New Dataset\n",
    "# print(\"\\nCreating new dataset\\n\")\n",
    "\n",
    "# # Create new coordinates within the subsetted data\n",
    "# vads_sub['lat']=vads_sub.lat.rename({'lat':'lat_va'})\n",
    "# vads_sub['lon']=vads_sub.lon.rename({'lon':'lon_va'})\n",
    "\n",
    "# uads_sub['lat']=uads_sub.lat.rename({'lat':'lat_ua'})\n",
    "# uads_sub['lon']=uads_sub.lon.rename({'lon':'lon_ua'})\n",
    "\n",
    "# vads_sub['uv_lev']=vads_sub.lev.rename({'lev':'uv_lev'})\n",
    "# uads_sub['uv_lev']=uads_sub.lev.rename({'lev':'uv_lev'})\n",
    "\n",
    "# # Create New Datasets that's just the datasets with dimensions and coordinates\n",
    "\n",
    "# ds_orog = xr.Dataset({\"orog\":((\"lat\",\"lon\"),tads_sub.orog)},\n",
    "#                  coords={\"lat\":tads_sub.lat,\"lon\":tads_sub.lon})\n",
    "\n",
    "# ds_prec = xr.Dataset({\"prc\":((\"time\",\"lat\",\"lon\"),prc6HrSub)},\n",
    "#                  coords={\"time\":tads_sub.time,\"lat\":tads_sub.lat,\"lon\":tads_sub.lon})\n",
    "\n",
    "# ds_ta   = xr.Dataset({\"ta\":((\"time\",\"lev\",\"lat\",\"lon\"),tads_sub.ta)},\n",
    "#                  coords={\"time\":tads_sub.time,\"lev\":tads_sub.lev,\"lat\":tads_sub.lat,\"lon\":tads_sub.lon})\n",
    "\n",
    "# ds_hus  = xr.Dataset({\"hus\":((\"time\",\"lev\",\"lat\",\"lon\"),husds_sub.hus)},\n",
    "#                  coords={\"time\":husds_sub.time,\"lev\":husds_sub.lev,\"lat\":husds_sub.lat,\"lon\":husds_sub.lon})\n",
    "\n",
    "# ds_v    = xr.Dataset({\"v\":((\"time\",\"uv_lev\",\"lat_va\",\"lon_va\"),vads_sub.va)},\n",
    "#                  coords={\"time\":vads_sub.time,\"uv_lev\":vads_sub.uv_lev,\"lat_va\":vads_sub.lat_va,\"lon_va\":vads_sub.lon_va})\n",
    "\n",
    "# ds_u    = xr.Dataset({\"u\":((\"time\",\"uv_lev\",\"lat_ua\",\"lon_ua\"),uads_sub.ua)},\n",
    "#                  coords={\"time\":uads_sub.time,\"uv_lev\":uads_sub.uv_lev,\"lat_ua\":uads_sub.lat_ua,\"lon_ua\":uads_sub.lon_ua})\n",
    "\n",
    "# # Make a new dataset\n",
    "# ds=xr.merge([ds_orog,ds_prec,ds_ta,ds_hus,ds_v,ds_u],compat='override')\n",
    "\n",
    "# print(\"Created new dataset\")\n",
    "\n",
    "# # Temperature\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# p = ds['ta'][0,0,:,:].plot(x='lon', y='lat',transform=ccrs.PlateCarree(),subplot_kws={'projection': ccrs.PlateCarree()})\n",
    "# ax.coastlines();ax.gridlines();ax.add_geometries(states_gdf.geometry, crs = ccrs.PlateCarree(),facecolor='none', edgecolor='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
